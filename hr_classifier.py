# -*- coding: utf-8 -*-
"""hr_classifier_backup.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14vmv676bxy7rjqmMIEvNADOP7Ch7qwfB
"""

# Cell 1 — Mounting my Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Cell 2 — Gathering file lists
import os, glob, re

DATA_DIR = '/content/drive/MyDrive/Colab Notebooks/csv_spo2hr'
all_paths = sorted(glob.glob(os.path.join(DATA_DIR, 'Subject*_SpO2HR.csv')))

TEST_SUBJS = {19, 20} # hard-coded the test subjects
train_paths, test_paths = [], []

for p in all_paths:
    sid = int(re.search(r'Subject(\d+)_SpO2HR\.csv', p).group(1))
    if sid in TEST_SUBJS:
        test_paths.append(p)
    else:
        train_paths.append(p)

print("Training on subjects:", sorted({int(re.search(r'Subject(\d+)', p).group(1)) for p in train_paths}))
print("Testing on subjects: ", sorted(TEST_SUBJS))

# Cell 3 — Building 60 s windows & extracting features
import numpy as np
import pandas as pd
import re

# cumulative end-times of stages in seconds
cum = np.cumsum([300, 300, 300, 40, 5*60, 300, 300])

def make_windows(paths, win=60):
    """Return DataFrame with columns subject, start, label, mean_hr, std_hr, min_hr, max_hr."""
    records = []

    for fp in paths: #looping over each csv file
        sid = int(re.search(r'Subject(\d+)', fp).group(1)) # subject id in the file name
        df  = pd.read_csv(fp).rename(columns={'time_s':'time','hr':'HR'})
        if 'time' not in df:
            df['time'] = np.arange(len(df))
        max_t = int(df['time'].max()) // win * win

        for t0 in range(0, max_t, win):
            win_df = df[(df['time'] >= t0) & (df['time'] < t0 + win)]
            # discard any incomplete windows
            if len(win_df) < win:
                continue

            mid = t0 + win/2
            lbl = 'Cognitive Stress' if (cum[3] < mid <= cum[4]) else 'Relaxed'

            records.append({
                'subject': sid,
                'start':   t0,
                'label':   lbl,
                'mean_hr': win_df['HR'].mean(),
                'std_hr':  win_df['HR'].std(),
                'min_hr':  win_df['HR'].min(),
                'max_hr':  win_df['HR'].max()
            })

    return pd.DataFrame(records)

df_train = make_windows(train_paths)
df_test  = make_windows(test_paths)

print("Train counts:\n", df_train['label'].value_counts())
print("Test counts:\n", df_test['label'].value_counts())
#print(df_test[5:30]) # just for debugging

# Cell 4 — LDA + SVM with Group-aware CV & Grid Search
import os
import pandas as pd
from sklearn.pipeline            import Pipeline
from sklearn.preprocessing       import StandardScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.svm                 import SVC
from sklearn.model_selection     import GridSearchCV, GroupKFold

# Merging subject info
info = pd.read_csv(os.path.join(DATA_DIR, 'subjectinfo.csv'))
df_train = df_train.merge(info, on='subject')
df_train['gender_code'] = df_train['gender'].map({'M':1, 'F':0}) # assigning male to 1 and female 0
# print(df_train) # for debugging

# Prepare training arrays - 6 features
FEATURES = ['mean_hr','std_hr','min_hr','max_hr', 'gender_code', 'age']
X_train = df_train[FEATURES].values
y_train = df_train['label'].values
groups  = df_train['subject'].values

#Pipeline: scale → LDA → SVM
pipe = Pipeline([
    ('scale', StandardScaler()),
    ('lda',   LinearDiscriminantAnalysis(n_components=1)),
    ('svm',   SVC(kernel='rbf', class_weight='balanced'))
])

# 4) Hyperparameter grid (we still tune only the SVM params)
param_grid = {
    'svm__C':     [0.1, 1, 10],
    'svm__gamma': ['scale', 'auto', 0.01, 0.1]
}


cv = GroupKFold(n_splits=5) # using group K Fold
search = GridSearchCV(pipe, param_grid,
                      cv=cv.split(X_train, y_train, groups),
                      scoring='accuracy', n_jobs=-1)


search.fit(X_train, y_train) # run grid search on training data
best_model = search.best_estimator_
print("Best params:", search.best_params_)

# Cell 5 — Evaluate on held-out subjects
from sklearn.metrics import accuracy_score, classification_report

# Merge demographics into test set & encode gender
df_test = df_test.merge(info, on='subject')
df_test['gender_code'] = df_test['gender'].map({'M':1, 'F':0})

X_test = df_test[FEATURES].values
y_test = df_test['label'].values

# Predict & evaluate
y_pred = best_model.predict(X_test)
print("Final test accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, digits=3))

# Cell 6 — Plot true vs. predicted stress over time for Subjects 19 & 20
import matplotlib.pyplot as plt

# Re-create test windows with start times
df_plot = make_windows(test_paths).merge(info, on='subject')
df_plot['gender_code'] = df_plot['gender'].map({'M':1, 'F':0})
df_plot['predicted']   = best_model.predict(df_plot[FEATURES].values)

# Map labels to 0/1 for plotting
map_y = {'Relaxed':0, 'Cognitive Stress':1}
df_plot['true_num'] = df_plot['label'].map(map_y)
df_plot['pred_num'] = df_plot['predicted'].map(map_y)

for subj in sorted(df_plot['subject'].unique()):
    sub   = df_plot[df_plot['subject']==subj]
    times = sub['start'] / 60.0  # convert seconds → minutes

    plt.figure(figsize=(10,2))
    plt.scatter(times, sub['true_num'], label='True', marker='o', alpha=0.7)
    plt.scatter(times, sub['pred_num'], label='Pred', marker='x', alpha=0.9)
    plt.yticks([0,1], ['Relaxed','Cognitive Stress'])
    plt.xlabel('Time (minutes)')
    plt.title(f'Subject {subj:02d} — True vs Predicted')
    plt.legend(loc='upper right')
    plt.tight_layout()
    plt.show()